{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airlines = pd.read_csv(os.path.join(data_folder,\"airlines.csv\"),sep=';')\n",
    "df_airports = pd.read_csv(os.path.join(data_folder,\"airports.csv\"),sep=';')\n",
    "df_flights = pd.read_csv(os.path.join(data_folder,\"flights.csv\"),sep=';')\n",
    "df_planes = pd.read_csv(os.path.join(data_folder,\"planes.csv\"),sep=';')\n",
    "df_weather = pd.read_csv(os.path.join(data_folder,\"weather.csv\"),sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Perform a left join with flights and airlines by carrier field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights = df_flights.merge(df_airlines,on='carrier')\n",
    "#df_flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Create a histogram plot of air_time field of flights dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"histogram of air time\")\n",
    "plt.xlabel(\"air time in minutes\")\n",
    "plt.ylabel(\"number of flights\")\n",
    "histo = plt.hist(df_flights.air_time.dropna(),bins=100)\n",
    "plt.savefig(\"fig/hist_air_time.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Create a plot of number of flights per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['dep_date'] = df_flights.apply(lambda r : date(r['year'],r['month'],r['day']),axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb_flight_per_day = df_flights.reset_index().groupby('dep_date')['index'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"number of flight per departure date\")\n",
    "plt.xlabel(\"departure date\")\n",
    "plt.ylabel(\"number of flights\")\n",
    "plt.plot(df_nb_flight_per_day)\n",
    "plt.savefig('fig/nb_flight_per_day.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['dep_day_of_week'] = df_flights['dep_date'].apply(lambda x : x.weekday())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) What features would you use to forecast volume? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use the volume in the recent past it self, just like for a time serie prediction (SARIMA), the day of week, and all weather. The problem here is that we clearly not under the time serie assumption as it is known that flights volume has a seasonnality over the year and here we have a sample with the size of a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â (e) Perform a logistic regression to model volume (do not worry on overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['ond'] = df_flights[['origin','dest']].apply(lambda x : x['origin']+x['dest'],axis=1)\n",
    "df_flights['one'] = 1\n",
    "df_nb_flight_per_day = df_nb_flight_per_day.reset_index()\n",
    "df_nb_flight_per_day = df_nb_flight_per_day.rename(columns={'index':'nb_flight'})\n",
    "df_weather['dep_date'] = df_weather.apply(lambda r : date(r['year'],r['month'],r['day']),axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb_flights_orig = df_flights.groupby(['dep_date','origin'])['one'].count().reset_index().pivot_table(values='one',index='dep_date',columns='origin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb_flights_orig['nb_flight_ground_truth'] = df_nb_flights_orig.apply(lambda x : x['EWR'] + x['JFK'] + x['LGA'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather=df_weather[[col for col in df_weather.columns if col not in ['year','month','day','hour']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_orig_pivot = df_weather.pivot_table(values=[col for col in df_weather.columns if col not in ['dep_date','origin']],index='dep_date',columns='origin').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_nb_flights_orig.reset_index().merge(df_weather_orig_pivot,on='dep_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['dep_day_of_week'] = df_features['dep_date'].apply(lambda x : x.weekday())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Modelisation with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features[[col for col in df_features.columns if col not in ['dep_date','EWR','JFK','LGA','nb_flight_ground_truth']]]\n",
    "y = df_features['nb_flight_ground_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['predicted'] = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['modelisation_error'] = df_features['predicted'] - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.title(\"flight volume modelisation using logistic regression\")\n",
    "plt.plot(df_features[['dep_date','predicted','nb_flight_ground_truth','modelisation_error']].set_index('dep_date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) How would you select features in that logistic regression to use this model to forecast number of flights for the following next days? (no code needed for this question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will select meaningfull features available in the future. for example we could use predicted weather information. I will also use day of week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) (optional) Create a histogram plot of dep_delay field of flights dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"departure delay histogram\")\n",
    "plt.xlabel(\"departure delay in minutes\")\n",
    "plt.ylabel(\"distribution of delays\")\n",
    "dep_delay_hist = plt.hist(df_flights['dep_delay'].dropna(),bins=100)\n",
    "plt.savefig(\"fig/departure_delay_histogram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h) Discretize dep_delay variable into dep_delay_cat, where values equal or below zero are a category itself, and the rest are categorized by deciles. Keep missing values as missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = df_flights[df_flights.dep_delay > 0].dep_delay.quantile(q=list(map(lambda x : x/10,range(0,10)))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles['index'] = deciles.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciles = deciles.dep_delay.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretization(x):\n",
    "    if x <= 0 :\n",
    "        return -1\n",
    "    if x <= deciles[0] :\n",
    "        return 0\n",
    "    if x > deciles[-1]:\n",
    "        return 9\n",
    "    if x == 1 :\n",
    "        return 0\n",
    "    for i in range(1,9):\n",
    "        if x > deciles[i] and x <= deciles[i+1]:\n",
    "            return i\n",
    "    if pd.isnull(x):\n",
    "        return pd.np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_delay_discretized = df_flights.dep_delay.apply(discretization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"histogram of discretized departure delay\")\n",
    "plt.xlabel(\"delay category\")\n",
    "plt.ylabel(\"distribution of the categories\")\n",
    "disc_delay_hist = plt.hist(dep_delay_discretized.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['dep_delay_discretized'] = df_flights.dep_delay.apply(discretization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Create a classification model and perform the evaluation of performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmuns = list(filter(lambda x : x not in ['year','month','day','dep_delay',\n",
    "                                          'sched_arr_time','flight','tailnum',\n",
    "                                          'air_time','dest','hour','minute','time_hour',\n",
    "                                          'dep_date','ond'], df_flights.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colmuns = list(filter(lambda x : x != 'origin', df_flights.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights['time_hour'] = df_flights.apply(lambda r : datetime(r['year'],r['month'],r['day'],r['hour']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['time_hour'] = df_weather.time_hour.apply(lambda x : datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â Dealing with missing values on weather using simple imputation by linear interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that data is missing under MCAR hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_list = list()\n",
    "for k,g in df_weather.groupby('origin'):\n",
    "    g = g.set_index('time_hour').resample('H').interpolate('linear')\n",
    "    g.origin = g.origin.fillna(value=k)\n",
    "    weather_data_list.append(g)\n",
    "df_weather_imputed = pd.concat(weather_data_list).reset_index()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dep_date' in df_weather_imputed.columns :\n",
    "    del df_weather_imputed['dep_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights_weather = df_flights.merge(df_weather_imputed,on=['time_hour','origin'],how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we remove rows with missing values related to depature time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"rows number before missing values drop {0}\".format(df_flights_weather.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights_weather = df_flights_weather.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"rows number after missing values drop {0}\".format(df_flights_weather.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_cols = [col for col in df_weather_imputed.columns if col not in ['time_hour','origin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights_cols = ['distance','dep_day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_all = df_flights_weather[weather_cols+df_flights_cols]\n",
    "#y_all = df_flights_weather['dep_delay_discretized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = LabelEncoder()\n",
    "onehot_encode = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_carrier_label = label_encode.fit_transform(df_flights_weather.carrier).reshape(*X_all.carrier.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_carrier = onehot_encode.fit_transform(encoded_carrier_label.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_mapping = dict(zip(list(range(16)),label_encode.inverse_transform(list(range(16)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carrier_endoced = pd.DataFrame(encoded_carrier,columns=list(carrier_mapping.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights_weather = df_flights_weather.join(df_carrier_endoced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df_flights_weather[weather_cols+df_flights_cols+list(carrier_mapping.values())]\n",
    "X_all_no_carrier = df_flights_weather[weather_cols+df_flights_cols]\n",
    "y_all = df_flights_weather['dep_delay_discretized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We take care of imbalanced data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_delay_discretized_distrib = y_all.reset_index().groupby('dep_delay_discretized').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_delay_discretized_distrib = 1/ dep_delay_discretized_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = dict(\n",
    "    (dep_delay_discretized_distrib / sum(map(lambda x : x[1],dep_delay_discretized_distrib.reset_index().values))).reset_index().values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(\"entropy\",random_state=0, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_params = {'n_estimators': 1000, 'max_leaf_nodes': 4, 'max_depth': None, 'random_state': 2,\n",
    "                   'min_samples_split': 5}\n",
    "gbt = GradientBoostingClassifier(**original_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(C=1e5,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(decision_tree,X_all_no_carrier,y_all,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree.fit(X_all_no_carrier.iloc[100000:300000],y_all.iloc[100000:300000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(decision_tree.predict(X_all_no_carrier.iloc[5:100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.iloc[5:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(log_reg,X_all,y_all,cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(X_all.iloc[10000:30000],y_all.iloc[10000:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(log_reg.predict(X_all.iloc[5:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all.iloc[5:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (j) What is the performance you would predict in production for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
